{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F#i assume this is the functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets define our neural network\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(2, 2)\n",
    "    #we define this function to tell the network how to pass the input through the network.\n",
    "    #the backwards function will automatically be defines using autograd\n",
    "    def forward(self, x):\n",
    "        x = (self.fc1(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Perceptron()\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor = pd.DataFrame({'X1':[0.,0.,1.,1.], 'X2':[0.,1.,0.,1.], 'y':[0,1,1,0]})\n",
    "xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets load in our datasets:\n",
    "import torch.utils.data as data_utils\n",
    "#Why do we have to use from numpy?\n",
    "features = torch.from_numpy(xor.iloc[:,:2].values).float()\n",
    "targets = torch.from_numpy(xor.iloc[:,2].values).long()\n",
    "train = data_utils.TensorDataset(features, targets)\n",
    "trainloader = data_utils.DataLoader(train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "epochs = 1\n",
    "criterion = F.cross_entropy#loss function\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=0.001)\n",
    "for epoch in range(100):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        x, labels = data\n",
    "        # zero the parameter gradients, we do not want to keep adding to the gradient after each minibatch\n",
    "        #what if we didnt do this?\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward\n",
    "        y_hat = classifier(x)\n",
    "        loss = criterion(y_hat, labels)#get the loss between the target and output, gets us our error\n",
    "        running_loss += loss\n",
    "        #backwards\n",
    "        loss.backward()#back prop\n",
    "        \n",
    "        #Gradient Descent\n",
    "        optimizer.step()#perform stochastic gradient desent.\n",
    "    print('loss: {}'.format(running_loss/len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Testing set results\n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = xor.iloc[:,:2].values, xor.iloc[:,2].values\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "input_ = torch.tensor(np.array([X1.ravel(), X2.ravel()]).T).float()\n",
    "plt.contourf(X1, X2, torch.argmax(classifier(input_), dim=1).detach().numpy().reshape(X1.shape),\n",
    "             alpha = 0.5, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('XOR problem 3 classes - Iris Dataset')\n",
    "plt.xlabel('petal-length')\n",
    "plt.ylabel('petal-width')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
